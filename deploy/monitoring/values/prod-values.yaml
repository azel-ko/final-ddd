# Production environment monitoring configuration
# This file contains production-specific overrides

global:
  imageRegistry: ""
  imagePullSecrets: []

prometheus:
  retention: "30d"
  retentionSize: "50GB"
  
  resources:
    requests:
      memory: "2Gi"
      cpu: "500m"
    limits:
      memory: "8Gi"
      cpu: "2000m"
  
  storage:
    enabled: true
    size: "100Gi"
    storageClass: "fast-ssd"
  
  config:
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'production'
        environment: 'prod'
  
  # High availability setup
  replicaCount: 2
  
  # Enhanced security
  securityContext:
    runAsNonRoot: true
    runAsUser: 65534
    fsGroup: 65534
  
  # Production alerting rules
  additionalRules:
    - name: production-critical
      rules:
        - alert: ProductionServiceDown
          expr: up{job="final-ddd-app",environment="prod"} == 0
          for: 30s
          labels:
            severity: critical
            environment: production
          annotations:
            summary: "CRITICAL: Production service is down"
            description: "Production application has been down for more than 30 seconds."

grafana:
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  
  persistence:
    enabled: true
    size: "20Gi"
    storageClass: "fast-ssd"
  
  # Production security settings
  securityContext:
    runAsNonRoot: true
    runAsUser: 472
    fsGroup: 472
  
  # SMTP configuration for production alerts
  smtp:
    enabled: true
    host: "smtp.yourdomain.com:587"
    user: "alerts@yourdomain.com"
    password: "your-smtp-password"
    fromAddress: "alerts@yourdomain.com"
    fromName: "Production Monitoring"
  
  # Production ingress
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: "traefik"
      traefik.ingress.kubernetes.io/router.tls.certresolver: "letsencrypt"
      traefik.ingress.kubernetes.io/router.middlewares: "monitoring-auth@kubernetescrd"
    hosts:
      - host: grafana.yourdomain.com
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.yourdomain.com

loki:
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  
  persistence:
    enabled: true
    size: "100Gi"
    storageClass: "fast-ssd"
  
  # Production log retention
  config:
    limits_config:
      retention_period: "720h"  # 30 days
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      ingestion_rate_mb: 16
      ingestion_burst_size_mb: 32
    
    # S3 storage for production (optional)
    storage_config:
      aws:
        s3: "s3://your-loki-bucket/loki"
        region: "us-west-2"
        access_key_id: "${AWS_ACCESS_KEY_ID}"
        secret_access_key: "${AWS_SECRET_ACCESS_KEY}"

promtail:
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  
  # Enhanced log collection for production
  config:
    scrape_configs:
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: node
          - replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]
            target_label: __path__
      
      # System logs
      - job_name: syslog
        static_configs:
          - targets:
              - localhost
            labels:
              job: syslog
              __path__: /var/log/syslog

alertmanager:
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  
  persistence:
    enabled: true
    size: "10Gi"
    storageClass: "fast-ssd"
  
  # Production alerting configuration
  config:
    global:
      smtp_smarthost: 'smtp.yourdomain.com:587'
      smtp_from: 'alerts@yourdomain.com'
      smtp_auth_username: 'alerts@yourdomain.com'
      smtp_auth_password: 'your-smtp-password'
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 5s
      group_interval: 5s
      repeat_interval: 12h
      receiver: 'production-alerts'
      routes:
        - match:
            severity: critical
          receiver: 'critical-alerts'
          group_wait: 0s
          repeat_interval: 5m
    
    receivers:
      - name: 'production-alerts'
        email_configs:
          - to: 'team@yourdomain.com'
            subject: '[PROD] {{ .GroupLabels.alertname }}'
            body: |
              {{ range .Alerts }}
              Alert: {{ .Annotations.summary }}
              Description: {{ .Annotations.description }}
              {{ end }}
        webhook_configs:
          - url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            send_resolved: true
      
      - name: 'critical-alerts'
        email_configs:
          - to: 'oncall@yourdomain.com'
            subject: '[CRITICAL] {{ .GroupLabels.alertname }}'
            body: |
              CRITICAL ALERT - IMMEDIATE ACTION REQUIRED
              {{ range .Alerts }}
              Alert: {{ .Annotations.summary }}
              Description: {{ .Annotations.description }}
              {{ end }}
        webhook_configs:
          - url: 'https://hooks.slack.com/services/YOUR/CRITICAL/WEBHOOK'
            send_resolved: true

nodeExporter:
  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "256Mi"
      cpu: "200m"

kubeStateMetrics:
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "512Mi"
      cpu: "500m"

# Production-specific network policies
networkPolicy:
  enabled: true
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
        - namespaceSelector:
            matchLabels:
              name: default
      ports:
        - protocol: TCP
          port: 9090  # Prometheus
        - protocol: TCP
          port: 3000  # Grafana
        - protocol: TCP
          port: 3100  # Loki